{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08dacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8de7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hasil_Text_Preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f420b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533b59ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>casefolding</th>\n",
       "      <th>tweetspecial</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>whitespace</th>\n",
       "      <th>multiplewhitespace</th>\n",
       "      <th>singlechar</th>\n",
       "      <th>wordtokenize</th>\n",
       "      <th>frekuensitoken</th>\n",
       "      <th>filtering</th>\n",
       "      <th>normalisasi</th>\n",
       "      <th>stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luar kota masuk Sidoarjo langsung digiring vak...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>luar kota masuk sidoarjo langsung digiring vak...</td>\n",
       "      <td>luar kota masuk sidoarjo langsung digiring vak...</td>\n",
       "      <td>luar kota masuk sidoarjo langsung digiring vak...</td>\n",
       "      <td>luar kota masuk sidoarjo langsung digiring vak...</td>\n",
       "      <td>luar kota masuk sidoarjo langsung digiring vak...</td>\n",
       "      <td>luar kota masuk sidoarjo langsung digiring vak...</td>\n",
       "      <td>['luar', 'kota', 'masuk', 'sidoarjo', 'langsun...</td>\n",
       "      <td>&lt;FreqDist with 11 samples and 11 outcomes&gt;</td>\n",
       "      <td>['kota', 'masuk', 'sidoarjo', 'langsung', 'dig...</td>\n",
       "      <td>['kota', 'masuk', 'sidoarjo', 'langsung', 'dig...</td>\n",
       "      <td>['kota', 'masuk', 'sidoarjo', 'langsung', 'gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>semoga anak 13 tahun bisa jadi anime dengan va...</td>\n",
       "      <td>['semoga', 'anak', '13', 'tahun', 'bisa', 'jad...</td>\n",
       "      <td>&lt;FreqDist with 11 samples and 11 outcomes&gt;</td>\n",
       "      <td>['semoga', 'anak', '13', 'anime', 'vaksin', 't...</td>\n",
       "      <td>['semoga', 'anak', '13', 'anime', 'vaksin', 't...</td>\n",
       "      <td>['moga', 'anak', '13', 'anime', 'vaksin', 'awan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dari data yang dikeluarkan oleh UK Health Safe...</td>\n",
       "      <td>positif</td>\n",
       "      <td>dari data yang dikeluarkan oleh uk health safe...</td>\n",
       "      <td>dari data yang dikeluarkan oleh uk health safe...</td>\n",
       "      <td>dari data yang dikeluarkan oleh uk health safe...</td>\n",
       "      <td>dari data yang dikeluarkan oleh uk health safe...</td>\n",
       "      <td>dari data yang dikeluarkan oleh uk health safe...</td>\n",
       "      <td>dari data yang dikeluarkan oleh uk health safe...</td>\n",
       "      <td>['dari', 'data', 'yang', 'dikeluarkan', 'oleh'...</td>\n",
       "      <td>&lt;FreqDist with 19 samples and 19 outcomes&gt;</td>\n",
       "      <td>['data', 'dikeluarkan', 'uk', 'health', 'safet...</td>\n",
       "      <td>['data', 'dikeluarkan', 'uk', 'health', 'safet...</td>\n",
       "      <td>['data', 'keluar', 'uk', 'health', 'safety', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAIS akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>positif</td>\n",
       "      <td>jais akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>jais akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>jais akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>jais akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>jais akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>jais akan meneliti semula perkara itu selaras ...</td>\n",
       "      <td>['jais', 'akan', 'meneliti', 'semula', 'perkar...</td>\n",
       "      <td>&lt;FreqDist with 17 samples and 17 outcomes&gt;</td>\n",
       "      <td>['jais', 'meneliti', 'perkara', 'selaras', 'ke...</td>\n",
       "      <td>['jais', 'meneliti', 'perkara', 'selaras', 'ke...</td>\n",
       "      <td>['jais', 'teliti', 'perkara', 'selaras', 'putu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Di USA udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>positif</td>\n",
       "      <td>di usa udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>di usa udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>di usa udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>di usa udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>di usa udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>di usa udah dikurang2in laporan efek samping v...</td>\n",
       "      <td>['di', 'usa', 'udah', 'dikurang2in', 'laporan'...</td>\n",
       "      <td>&lt;FreqDist with 28 samples and 30 outcomes&gt;</td>\n",
       "      <td>['usa', 'udah', 'dikurang2in', 'laporan', 'efe...</td>\n",
       "      <td>['usa', 'sudah', 'dikurang2in', 'laporan', 'ef...</td>\n",
       "      <td>['usa', 'sudah', 'dikurang2in', 'lapor', 'efek...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text sentimen  \\\n",
       "0  Luar kota masuk Sidoarjo langsung digiring vak...  negatif   \n",
       "1  Semoga anak 13 tahun bisa jadi anime dengan va...  negatif   \n",
       "2  Dari data yang dikeluarkan oleh UK Health Safe...  positif   \n",
       "3  JAIS akan meneliti semula perkara itu selaras ...  positif   \n",
       "4  Di USA udah dikurang2in laporan efek samping v...  positif   \n",
       "\n",
       "                                         casefolding  \\\n",
       "0  luar kota masuk sidoarjo langsung digiring vak...   \n",
       "1  semoga anak 13 tahun bisa jadi anime dengan va...   \n",
       "2  dari data yang dikeluarkan oleh uk health safe...   \n",
       "3  jais akan meneliti semula perkara itu selaras ...   \n",
       "4  di usa udah dikurang2in laporan efek samping v...   \n",
       "\n",
       "                                        tweetspecial  \\\n",
       "0  luar kota masuk sidoarjo langsung digiring vak...   \n",
       "1  semoga anak 13 tahun bisa jadi anime dengan va...   \n",
       "2  dari data yang dikeluarkan oleh uk health safe...   \n",
       "3  jais akan meneliti semula perkara itu selaras ...   \n",
       "4  di usa udah dikurang2in laporan efek samping v...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  luar kota masuk sidoarjo langsung digiring vak...   \n",
       "1  semoga anak 13 tahun bisa jadi anime dengan va...   \n",
       "2  dari data yang dikeluarkan oleh uk health safe...   \n",
       "3  jais akan meneliti semula perkara itu selaras ...   \n",
       "4  di usa udah dikurang2in laporan efek samping v...   \n",
       "\n",
       "                                          whitespace  \\\n",
       "0  luar kota masuk sidoarjo langsung digiring vak...   \n",
       "1  semoga anak 13 tahun bisa jadi anime dengan va...   \n",
       "2  dari data yang dikeluarkan oleh uk health safe...   \n",
       "3  jais akan meneliti semula perkara itu selaras ...   \n",
       "4  di usa udah dikurang2in laporan efek samping v...   \n",
       "\n",
       "                                  multiplewhitespace  \\\n",
       "0  luar kota masuk sidoarjo langsung digiring vak...   \n",
       "1  semoga anak 13 tahun bisa jadi anime dengan va...   \n",
       "2  dari data yang dikeluarkan oleh uk health safe...   \n",
       "3  jais akan meneliti semula perkara itu selaras ...   \n",
       "4  di usa udah dikurang2in laporan efek samping v...   \n",
       "\n",
       "                                          singlechar  \\\n",
       "0  luar kota masuk sidoarjo langsung digiring vak...   \n",
       "1  semoga anak 13 tahun bisa jadi anime dengan va...   \n",
       "2  dari data yang dikeluarkan oleh uk health safe...   \n",
       "3  jais akan meneliti semula perkara itu selaras ...   \n",
       "4  di usa udah dikurang2in laporan efek samping v...   \n",
       "\n",
       "                                        wordtokenize  \\\n",
       "0  ['luar', 'kota', 'masuk', 'sidoarjo', 'langsun...   \n",
       "1  ['semoga', 'anak', '13', 'tahun', 'bisa', 'jad...   \n",
       "2  ['dari', 'data', 'yang', 'dikeluarkan', 'oleh'...   \n",
       "3  ['jais', 'akan', 'meneliti', 'semula', 'perkar...   \n",
       "4  ['di', 'usa', 'udah', 'dikurang2in', 'laporan'...   \n",
       "\n",
       "                               frekuensitoken  \\\n",
       "0  <FreqDist with 11 samples and 11 outcomes>   \n",
       "1  <FreqDist with 11 samples and 11 outcomes>   \n",
       "2  <FreqDist with 19 samples and 19 outcomes>   \n",
       "3  <FreqDist with 17 samples and 17 outcomes>   \n",
       "4  <FreqDist with 28 samples and 30 outcomes>   \n",
       "\n",
       "                                           filtering  \\\n",
       "0  ['kota', 'masuk', 'sidoarjo', 'langsung', 'dig...   \n",
       "1  ['semoga', 'anak', '13', 'anime', 'vaksin', 't...   \n",
       "2  ['data', 'dikeluarkan', 'uk', 'health', 'safet...   \n",
       "3  ['jais', 'meneliti', 'perkara', 'selaras', 'ke...   \n",
       "4  ['usa', 'udah', 'dikurang2in', 'laporan', 'efe...   \n",
       "\n",
       "                                         normalisasi  \\\n",
       "0  ['kota', 'masuk', 'sidoarjo', 'langsung', 'dig...   \n",
       "1  ['semoga', 'anak', '13', 'anime', 'vaksin', 't...   \n",
       "2  ['data', 'dikeluarkan', 'uk', 'health', 'safet...   \n",
       "3  ['jais', 'meneliti', 'perkara', 'selaras', 'ke...   \n",
       "4  ['usa', 'sudah', 'dikurang2in', 'laporan', 'ef...   \n",
       "\n",
       "                                             stemmer  \n",
       "0  ['kota', 'masuk', 'sidoarjo', 'langsung', 'gir...  \n",
       "1  ['moga', 'anak', '13', 'anime', 'vaksin', 'awan']  \n",
       "2  ['data', 'keluar', 'uk', 'health', 'safety', '...  \n",
       "3  ['jais', 'teliti', 'perkara', 'selaras', 'putu...  \n",
       "4  ['usa', 'sudah', 'dikurang2in', 'lapor', 'efek...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c44cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- TF-IDF on Tweet data -------\n",
      "TF-IDF  <class 'numpy.ndarray'> (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# banyaknya term yang akan digunakan, \n",
    "# di pilih berdasarkan top max_features \n",
    "# yang diurutkan berdasarkan term frequency seluruh corpus\n",
    "max_features = 1000\n",
    "\n",
    "# Feature Engineering \n",
    "print (\"------- TF-IDF on Tweet data -------\")\n",
    "\n",
    "tf_idf = TfidfVectorizer(max_features=max_features, binary=True)\n",
    "tfidf_mat = tf_idf.fit_transform(df[\"stemmer\"]).toarray()\n",
    "\n",
    "print(\"TF-IDF \", type(tfidf_mat), tfidf_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a1bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wearness\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>97.410740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>booster</td>\n",
       "      <td>40.099364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>sudah</td>\n",
       "      <td>38.477611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>tidak</td>\n",
       "      <td>31.057819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>yang</td>\n",
       "      <td>25.349065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>linu</td>\n",
       "      <td>0.509053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>pattallassang</td>\n",
       "      <td>0.492461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>berbagipenyaluran</td>\n",
       "      <td>0.458660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>kotak</td>\n",
       "      <td>0.458660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>nasi</td>\n",
       "      <td>0.458660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term       rank\n",
       "972             vaksin  97.410740\n",
       "155            booster  40.099364\n",
       "861              sudah  38.477611\n",
       "916              tidak  31.057819\n",
       "993               yang  25.349065\n",
       "..                 ...        ...\n",
       "521               linu   0.509053\n",
       "678      pattallassang   0.492461\n",
       "136  berbagipenyaluran   0.458660\n",
       "487              kotak   0.458660\n",
       "609               nasi   0.458660\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = tf_idf.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = tfidf_mat.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append((term, sums[col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "ranking.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9f070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "# calc TF vector\n",
    "cvect = CountVectorizer(max_features=max_features)\n",
    "TF_vector = cvect.fit_transform(df[\"stemmer\"])\n",
    "\n",
    "# normalize TF vector\n",
    "normalized_TF_vector = normalize(TF_vector, norm='l1', axis=1)\n",
    "\n",
    "# calc IDF\n",
    "tfidf = TfidfVectorizer(max_features=max_features, smooth_idf=False)\n",
    "tfs = tfidf.fit_transform(df[\"stemmer\"])\n",
    "IDF_vector = tfidf.idf_\n",
    "\n",
    "# hitung TF x IDF sehingga dihasilkan TFIDF matrix / vector\n",
    "tfidf_mat = normalized_TF_vector.multiply(IDF_vector).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70af7b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60a288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
